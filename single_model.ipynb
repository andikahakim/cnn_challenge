{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "!pip install pycm livelossplot\n",
    "%pylab inline\n",
    "from sklearn.metrics          import accuracy_score\n",
    "from sklearn.preprocessing    import StandardScaler\n",
    "from sklearn.model_selection  import StratifiedShuffleSplit\n",
    "from livelossplot             import PlotLosses\n",
    "from pycm                     import *\n",
    "from torch.utils.data         import Dataset\n",
    "from torchvision.transforms   import Compose, ToTensor, Normalize, RandomRotation, ToPILImage, RandomHorizontalFlip, RandomVerticalFlip, RandomAffine, ColorJitter, Lambda, Resize\n",
    "from torch.utils.data         import TensorDataset, DataLoader, random_split\n",
    "from torchvision.datasets     import ImageFolder\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn               as nn\n",
    "import torch.nn.functional    as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models     as models\n",
    "import matplotlib.pyplot      as plt\n",
    "import numpy                  as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "plt.style.use('seaborn-deep')\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = True  # uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
    "    torch.backends.cudnn.enabled   = True\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
    "    print(\"Cuda installed! Running on GPU!\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"No GPU available!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "path = '../input/acseminiproject/'\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## transformations & normalisation ##\n",
    "\n",
    "# training set transformation:\n",
    "raw_transform_train = Compose([\n",
    "    Resize(224),                                                                                                                                                                                                                                                                                          \n",
    "    ToTensor(), \n",
    "    Normalize(mean=[0.4802, 0.4481, 0.3975],\n",
    "                         std=[0.277, 0.2691, 0.2821]),\n",
    "])\n",
    "\n",
    "# validation set transformation:\n",
    "raw_transform_valid = Compose([\n",
    "    Resize(224),                                                                                                                                                                                                                                                                                            \n",
    "    ToTensor(), \n",
    "    Normalize(mean=[0.4802, 0.4481, 0.3975],\n",
    "                         std=[0.277, 0.2691, 0.2821]),\n",
    "])\n",
    "\n",
    "\n",
    "# download the raw data, apply transformations and normalisation:\n",
    "train_data_raw = ImageFolder(path+'train', transform=raw_transform_train)\n",
    "test_data_raw = ImageFolder(path+'test', transform=raw_transform_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## optimal hyperparameters ## \n",
    "\n",
    "seed = 42\n",
    "lr = 5e-4 # learning rate\n",
    "momentum = 0.6 # optimisation momentum parameter\n",
    "batch_size = 64 # training batch size\n",
    "test_batch_size = 500 # test batch size \n",
    "n_epochs = 7 # number of epochs to train over\n",
    "weight_decay = 1e-5 # L2 weight-decay parameter\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_val_loaders(validation=True, split=0.8):\n",
    "    \n",
    "    \"\"\"\n",
    "    Explanation:\n",
    "        This function instantiates data loaders\n",
    "    Args:\n",
    "        validation (bool): if True then will split data\n",
    "        split (float): gives training/validation split, 0.8 corresponds to 80/20\n",
    "    Returns:\n",
    "        train_loader: DataLoader for training data\n",
    "        validation_loader: DataLoader for validation data\n",
    "    \"\"\"\n",
    "    \n",
    "    if validation == True:\n",
    "        \"\"\"splitting into validation and training dataseta\"\"\"\n",
    "        train_size = int(split * len(train_data_raw))\n",
    "        validation_size = len(train_data_raw) - train_size\n",
    "\n",
    "        # split up the data\n",
    "        train_dataset, validation_dataset = random_split(train_data_raw, [train_size, validation_size])\n",
    "\n",
    "        # instantiate DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)                                    \n",
    "        validation_loader = DataLoader(validation_dataset, batch_size=test_batch_size, shuffle=False, num_workers=0)   \n",
    "        return train_loader, validation_loader\n",
    "    \n",
    "    else:\n",
    "        \"\"\"using the whole dataset to train\"\"\"\n",
    "        # final case, where we train the model using all of the available data:\n",
    "        train_loader = DataLoader(train_data_raw, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "#         print(len(train_loader.dataset)) # check length\n",
    "        return train_loader, 0\n",
    "\n",
    "\n",
    "train_loader, validation_loader = generate_train_val_loaders(validation=True, split=0.8)\n",
    "\n",
    "# # check it's working:\n",
    "# print(len(train_loader.dataset)) # check length\n",
    "# print(len(validation_loader.dataset)) # check length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostly fixed CUDA out of memory problem\n",
    "model = None\n",
    "learn = None\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define our CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_model(name, printmod=True):\n",
    "    \"\"\"\n",
    "    Explanation:\n",
    "        This function chooses the desired model, pre-trained, change output layer as we have 200 classes\n",
    "    Args:\n",
    "        name (string): name of model\n",
    "        printmod (bool): will print model if True  \n",
    "    Returns:\n",
    "        model: the desired CNN, with output layer set to 200\n",
    "    \"\"\"\n",
    "    if name == \"resnet18\":\n",
    "        model = models.resnet18(pretrained=True).to(device)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, 200)\n",
    "        \n",
    "    elif name == \"resnext50_32x4d\":\n",
    "        model = models.resnext50_32x4d(pretrained=True).to(device)  \n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, 200)\n",
    "\n",
    "    elif name == \"wide_resnet101_2\":\n",
    "        model = models.wide_resnet101_2(pretrained=True).to(device)  \n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, 200)\n",
    "        \n",
    "    elif name == \"vgg19_bn\":\n",
    "        vggmodel = models.vgg19_bn(pretrained=True).to(device) \n",
    "        num_ftrs =  vggmodel.classifier[6].in_features\n",
    "        vggmodel.classifier[6] = nn.Linear(num_ftrs,200)\n",
    "\n",
    "    else:\n",
    "        print(\"please input a valid model name.\")\n",
    "        \n",
    "    if printmod == True:\n",
    "        print(model)\n",
    "        \n",
    "    return model.to(device)\n",
    "\n",
    "model = choose_model(\"wide_resnet101_2\", printmod=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE - if using model to predict test data (i.e. not training), then skip 4. & 5. below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training, evaluation and validation functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## note - for resnet (224 shape). If you wish to re-use this code with a different model you may have to change dimensions within the code ##\n",
    "def train(model, optimizer, criterion, data_loader):\n",
    "    model.train()\n",
    "    train_loss, train_accuracy = 0, 0\n",
    "    for X, y in data_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad() \n",
    "        a2 = model(X.view(-1, 3, 224 , 224))                                                                                     \n",
    "        loss = criterion(a2, y)\n",
    "        loss.backward()\n",
    "        train_loss += loss*X.size(0)\n",
    "        y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
    "        train_accuracy += accuracy_score(y.cpu().numpy(), y_pred.detach().cpu().numpy())*X.size(0)                            \n",
    "        optimizer.step()  \n",
    "    return train_loss/len(data_loader.dataset), train_accuracy/len(data_loader.dataset)\n",
    "\n",
    "def validate(model, criterion, data_loader):\n",
    "    model.eval()\n",
    "    validation_loss, validation_accuracy = 0., 0.\n",
    "    for X, y in data_loader:\n",
    "        with torch.no_grad():\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            a2 = model(X.view(-1, 3, 224 , 224))                                                                                                                                                                \n",
    "            loss = criterion(a2, y)\n",
    "            validation_loss += loss*X.size(0)\n",
    "            y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
    "            validation_accuracy += accuracy_score(y.cpu().numpy(), y_pred.cpu().numpy())*X.size(0)                              \n",
    "    return validation_loss/len(data_loader.dataset), validation_accuracy/len(data_loader.dataset)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "liveloss = PlotLosses()\n",
    "for epoch in range(n_epochs):\n",
    "    logs = {}\n",
    "    train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
    "    logs['' + 'log loss'] = train_loss.item()\n",
    "    logs['' + 'accuracy'] = train_accuracy.item()\n",
    "\n",
    "    validation_loss, validation_accuracy = validate(model, criterion, validation_loader)\n",
    "    logs['val_' + 'log loss'] = validation_loss.item()\n",
    "    logs['val_' + 'accuracy'] = validation_accuracy.item()\n",
    "\n",
    "    liveloss.update(logs)\n",
    "    liveloss.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Save our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_name = 'RESNET_101_wide_le5_fulldata.pth'\n",
    "path = F\"./{model_save_name}\"\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Generate predicted labels for test set in .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code is for loading Team Dropout model (in this case, we are showing wide_resnet101_2 and please make sure in section 4 to also choose wide_resnet101_2 model) Note that in GoogleDrive our best model is called \"best_resnet101wide_21_02_2020.pth\". Skip this part if user wish to use trained model from section 5\n",
    "Note : Please set the path to the directory you have stored the model in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(F\"../wide_resnet101_2_fulltrain.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader):\n",
    "    \"\"\"\n",
    "    Explanation:\n",
    "        This function makes predictions on the test data from a single model\n",
    "    Args:\n",
    "        model (Tensor): A pytorch neural net model\n",
    "        data_loader (DataLoader): A pytorch  dataloader for the test data    \n",
    "    Returns:\n",
    "        y_preds (np.array): An array  containing the class label predictions based on the softmax classifier\n",
    "        file_names: (np.array): An array containing the filenames; this is used to construct the kaggle submission\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    y_preds, file_names = [], []\n",
    "    for X, y,file_paths in data_loader:\n",
    "        with torch.no_grad():\n",
    "            # make sure we can utilize the GPU if available\n",
    "            X, y = torch.from_numpy(np.array(X)).to(device), y.to(device)\n",
    "            \n",
    "            # forward pass through the model\n",
    "            a2 = model(X)\n",
    "            # make the predictions based off our model\n",
    "            y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
    "            \n",
    "            # fix filenames\n",
    "            img_names = [name.split('/')[-1] for name in file_paths]\n",
    "            \n",
    "            # set up the return arrays\n",
    "            y_preds.append(y_pred.cpu().numpy())\n",
    "            file_names.extend(img_names)\n",
    "    return np.concatenate(y_preds, 0), np.array(file_names)\n",
    "\n",
    "\n",
    "# this is needed for the test function below. It loads the test dataset correctly\n",
    "class ImageFolderWithPaths(ImageFolder):\n",
    "    \"\"\"Custom dataset that also returns image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    Inspiration for this function from https://gist.github.com/andrewjong/6b02ff237533b3b2c554701fb53d5c4d\n",
    "    \"\"\"\n",
    "    # override the __getitem__ method. this is the method that dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../input/miniproject/'\n",
    "os.listdir(path+'test')\n",
    "\n",
    "# this transformation changes the PIL image to a tensor. This transform is only necessary for the test dataset as it uses ImageFolderWithPaths\n",
    "test_transform = Compose([\n",
    "    Resize(254),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.4802, 0.4481, 0.3975],\n",
    "                         std=[0.277, 0.2691, 0.2821]),\n",
    "])\n",
    "\n",
    "# Again assuming that the folder path is correct relative to file position\n",
    "os.listdir(path)\n",
    "test_data_raw = ImageFolderWithPaths(path+'test', transform=test_transform)\n",
    "test_loader = DataLoader(test_data_raw, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the predictions and construct the output dataframe\n",
    "y_preds, filenames = test(model, test_loader)\n",
    "# construct dataframe from the results\n",
    "submission = pd.DataFrame({'Filename': filenames, 'Label': y_preds})\n",
    "submission.head()\n",
    "submission.to_csv('wide_resnet101_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
